# LLM Serving in a Week

[Preface](./preface.md)
[Setting Up the Environment]()

---

- [Week 1: From Matmul to Text]()
    - [Attention and Multi-Head Attention, Linear]()
    - [Positional Embeddings and RoPE]()
    - [Grouped/Multi Query Attention, Embedding, Silu]()
    - [Multilayer Perceptron Layer and Transformer, RMSNorm]()
    - [Wiring and Loading the Model, Dequantize]()
    - [Tokenize and Generating Response]()

- [Week 2: Optimizing]()

- [Week 3: Serving]()

---

[Glossary Index](./glossary.md)
